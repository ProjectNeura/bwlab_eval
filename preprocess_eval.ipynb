{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "M74X2Bc2MWPN"
   ],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyPcZmHVYxkfA2RXbiZTL7nX",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ProjectNeura/bwlab_eval/blob/main/preprocess_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Dependencies"
   ],
   "metadata": {
    "id": "M74X2Bc2MWPN"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ED_Kk9awK-1N",
    "outputId": "5dac57b9-b4e0-4eed-f572-40443c50980d"
   },
   "source": "!pip3 install nnunetv2 acvl-utils",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Define Functions",
   "metadata": {
    "id": "nck9mZmYOtvI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from abc import abstractmethod, ABC\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Dict, Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from acvl_utils.cropping_and_padding.bounding_boxes import get_bbox_from_mask, bounding_box_to_slice\n",
    "from batchgenerators.augmentations.utils import resize_segmentation\n",
    "from nnunetv2.configuration import ANISO_THRESHOLD\n",
    "from scipy.ndimage import binary_fill_holes, map_coordinates\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "class ImageNormalization(ABC):\n",
    "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = None\n",
    "\n",
    "    def __init__(self, use_mask_for_norm: Optional[bool] = None, intensityproperties: Optional[Dict] = None,\n",
    "                 target_dtype: torch.dtype = torch.float32):\n",
    "        assert use_mask_for_norm is None or isinstance(use_mask_for_norm, bool)\n",
    "        self.use_mask_for_norm = use_mask_for_norm\n",
    "        assert isinstance(intensityproperties, dict) or intensityproperties is None\n",
    "        self.intensityproperties = intensityproperties\n",
    "        self.target_dtype = target_dtype\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, image: torch.Tensor, seg: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class CTNormalization(ImageNormalization):\n",
    "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = False\n",
    "\n",
    "    def run(self, image: np.ndarray, seg: np.ndarray = None) -> np.ndarray:\n",
    "        assert self.intensityproperties is not None, \"CTNormalization requires intensity properties\"\n",
    "        mean_intensity = self.intensityproperties['mean']\n",
    "        std_intensity = self.intensityproperties['std']\n",
    "        lower_bound = self.intensityproperties['percentile_00_5']\n",
    "        upper_bound = self.intensityproperties['percentile_99_5']\n",
    "\n",
    "        image = image.astype(self.target_dtype, copy=False)\n",
    "        np.clip(image, lower_bound, upper_bound, out=image)\n",
    "        image -= mean_intensity\n",
    "        image /= max(std_intensity, 1e-8)\n",
    "        return image\n",
    "\n",
    "\n",
    "def create_nonzero_mask(data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :return: the mask is True where the data is nonzero\n",
    "    \"\"\"\n",
    "    assert data.ndim in (3, 4), \"data must have shape (C, X, Y, Z) or shape (C, X, Y)\"\n",
    "    nonzero_mask = data[0] != 0\n",
    "    for c in range(1, data.shape[0]):\n",
    "        nonzero_mask |= data[c] != 0\n",
    "    return binary_fill_holes(nonzero_mask)\n",
    "\n",
    "\n",
    "def crop_to_nonzero(data, seg=None, nonzero_label=-1):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param seg:\n",
    "    :param nonzero_label: this will be written into the segmentation map\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nonzero_mask = create_nonzero_mask(data)\n",
    "    bbox = get_bbox_from_mask(nonzero_mask)\n",
    "    slicer = bounding_box_to_slice(bbox)\n",
    "    nonzero_mask = nonzero_mask[slicer][None]\n",
    "\n",
    "    slicer = (slice(None),) + slicer\n",
    "    data = data[slicer]\n",
    "    if seg is not None:\n",
    "        seg = seg[slicer]\n",
    "        seg[(seg == 0) & (~nonzero_mask)] = nonzero_label\n",
    "    else:\n",
    "        seg = np.where(nonzero_mask, np.int8(0), np.int8(nonzero_label))\n",
    "    return data, seg, bbox\n",
    "\n",
    "\n",
    "def get_do_separate_z(spacing: Union[Tuple[float, ...], List[float], np.ndarray], anisotropy_threshold=ANISO_THRESHOLD):\n",
    "    do_separate_z = (np.max(spacing) / np.min(spacing)) > anisotropy_threshold\n",
    "    return do_separate_z\n",
    "\n",
    "\n",
    "def get_lowres_axis(new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]):\n",
    "    axis = np.where(max(new_spacing) / np.array(new_spacing) == 1)[0]  # find which axis is anisotropic\n",
    "    return axis\n",
    "\n",
    "\n",
    "def determine_do_sep_z_and_axis(\n",
    "        force_separate_z: bool,\n",
    "        current_spacing,\n",
    "        new_spacing,\n",
    "        separate_z_anisotropy_threshold: float = ANISO_THRESHOLD) -> Tuple[bool, Union[int, None]]:\n",
    "    if force_separate_z is not None:\n",
    "        do_separate_z = force_separate_z\n",
    "        if force_separate_z:\n",
    "            axis = get_lowres_axis(current_spacing)\n",
    "        else:\n",
    "            axis = None\n",
    "    else:\n",
    "        if get_do_separate_z(current_spacing, separate_z_anisotropy_threshold):\n",
    "            do_separate_z = True\n",
    "            axis = get_lowres_axis(current_spacing)\n",
    "        elif get_do_separate_z(new_spacing, separate_z_anisotropy_threshold):\n",
    "            do_separate_z = True\n",
    "            axis = get_lowres_axis(new_spacing)\n",
    "        else:\n",
    "            do_separate_z = False\n",
    "            axis = None\n",
    "\n",
    "    if axis is not None:\n",
    "        if len(axis) == 3:\n",
    "            do_separate_z = False\n",
    "            axis = None\n",
    "        elif len(axis) == 2:\n",
    "            # this happens for spacings like (0.24, 1.25, 1.25) for example. In that case we do not want to resample\n",
    "            # separately in the out of plane axis\n",
    "            do_separate_z = False\n",
    "            axis = None\n",
    "        else:\n",
    "            axis = axis[0]\n",
    "    return do_separate_z, axis\n",
    "\n",
    "\n",
    "def resample_data_or_seg(data: np.ndarray, new_shape: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                         is_seg: bool = False, axis: Union[None, int] = None, order: int = 3,\n",
    "                         do_separate_z: bool = False, order_z: int = 0, dtype_out=None):\n",
    "    \"\"\"\n",
    "    separate_z=True will resample with order 0 along z\n",
    "    :param data:\n",
    "    :param new_shape:\n",
    "    :param is_seg:\n",
    "    :param axis:\n",
    "    :param order:\n",
    "    :param do_separate_z:\n",
    "    :param order_z: only applies if do_separate_z is True\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert data.ndim == 4, \"data must be (c, x, y, z)\"\n",
    "    assert len(new_shape) == data.ndim - 1\n",
    "\n",
    "    if is_seg:\n",
    "        resize_fn = resize_segmentation\n",
    "        kwargs = OrderedDict()\n",
    "    else:\n",
    "        resize_fn = resize\n",
    "        kwargs = {'mode': 'edge', 'anti_aliasing': False}\n",
    "    shape = np.array(data[0].shape)\n",
    "    new_shape = np.array(new_shape)\n",
    "    if dtype_out is None:\n",
    "        dtype_out = data.dtype\n",
    "    reshaped_final = np.zeros((data.shape[0], *new_shape), dtype=dtype_out)\n",
    "    if np.any(shape != new_shape):\n",
    "        data = data.astype(float, copy=False)\n",
    "        if do_separate_z:\n",
    "            # print(\"separate z, order in z is\", order_z, \"order inplane is\", order)\n",
    "            assert axis is not None, 'If do_separate_z, we need to know what axis is anisotropic'\n",
    "            if axis == 0:\n",
    "                new_shape_2d = new_shape[1:]\n",
    "            elif axis == 1:\n",
    "                new_shape_2d = new_shape[[0, 2]]\n",
    "            else:\n",
    "                new_shape_2d = new_shape[:-1]\n",
    "\n",
    "            for c in range(data.shape[0]):\n",
    "                tmp = deepcopy(new_shape)\n",
    "                tmp[axis] = shape[axis]\n",
    "                reshaped_here = np.zeros(tmp)\n",
    "                for slice_id in range(shape[axis]):\n",
    "                    if axis == 0:\n",
    "                        reshaped_here[slice_id] = resize_fn(data[c, slice_id], new_shape_2d, order, **kwargs)\n",
    "                    elif axis == 1:\n",
    "                        reshaped_here[:, slice_id] = resize_fn(data[c, :, slice_id], new_shape_2d, order, **kwargs)\n",
    "                    else:\n",
    "                        reshaped_here[:, :, slice_id] = resize_fn(data[c, :, :, slice_id], new_shape_2d, order,\n",
    "                                                                  **kwargs)\n",
    "                if shape[axis] != new_shape[axis]:\n",
    "\n",
    "                    # The following few lines are blatantly copied and modified from sklearn's resize()\n",
    "                    rows, cols, dim = new_shape[0], new_shape[1], new_shape[2]\n",
    "                    orig_rows, orig_cols, orig_dim = reshaped_here.shape\n",
    "\n",
    "                    # align_corners=False\n",
    "                    row_scale = float(orig_rows) / rows\n",
    "                    col_scale = float(orig_cols) / cols\n",
    "                    dim_scale = float(orig_dim) / dim\n",
    "\n",
    "                    map_rows, map_cols, map_dims = np.mgrid[:rows, :cols, :dim]\n",
    "                    map_rows = row_scale * (map_rows + 0.5) - 0.5\n",
    "                    map_cols = col_scale * (map_cols + 0.5) - 0.5\n",
    "                    map_dims = dim_scale * (map_dims + 0.5) - 0.5\n",
    "\n",
    "                    coord_map = np.array([map_rows, map_cols, map_dims])\n",
    "                    if not is_seg or order_z == 0:\n",
    "                        reshaped_final[c] = map_coordinates(reshaped_here, coord_map, order=order_z, mode='nearest')[\n",
    "                            None]\n",
    "                    else:\n",
    "                        unique_labels = np.sort(pd.unique(reshaped_here.ravel()))  # np.unique(reshaped_data)\n",
    "                        for i, cl in enumerate(unique_labels):\n",
    "                            reshaped_final[c][np.round(\n",
    "                                map_coordinates((reshaped_here == cl).astype(float), coord_map, order=order_z,\n",
    "                                                mode='nearest')) > 0.5] = cl\n",
    "                else:\n",
    "                    reshaped_final[c] = reshaped_here\n",
    "        else:\n",
    "            # print(\"no separate z, order\", order)\n",
    "            for c in range(data.shape[0]):\n",
    "                reshaped_final[c] = resize_fn(data[c], new_shape, order, **kwargs)\n",
    "        return reshaped_final\n",
    "    else:\n",
    "        # print(\"no resampling necessary\")\n",
    "        return data\n",
    "\n",
    "\n",
    "def resample_data_or_seg_to_shape(data: Union[torch.Tensor, np.ndarray],\n",
    "                                  new_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                                  current_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                  new_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                  is_seg: bool = False,\n",
    "                                  order: int = 3, order_z: int = 0,\n",
    "                                  force_separate_z: Union[bool, None] = False,\n",
    "                                  separate_z_anisotropy_threshold: float = ANISO_THRESHOLD):\n",
    "    \"\"\"\n",
    "    needed for segmentation export. Stupid, I know\n",
    "    \"\"\"\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.numpy()\n",
    "\n",
    "    do_separate_z, axis = determine_do_sep_z_and_axis(force_separate_z, current_spacing, new_spacing,\n",
    "                                                      separate_z_anisotropy_threshold)\n",
    "\n",
    "    if data is not None:\n",
    "        assert data.ndim == 4, \"data must be c x y z\"\n",
    "\n",
    "    data_reshaped = resample_data_or_seg(data, new_shape, is_seg, axis, order, do_separate_z, order_z=order_z)\n",
    "    return data_reshaped\n",
    "\n",
    "\n",
    "def compute_new_shape(old_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                      old_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                      new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]) -> np.ndarray:\n",
    "    assert len(old_spacing) == len(old_shape)\n",
    "    assert len(old_shape) == len(new_spacing)\n",
    "    new_shape = np.array([int(round(i / j * k)) for i, j, k in zip(old_spacing, new_spacing, old_shape)])\n",
    "    return new_shape"
   ],
   "metadata": {
    "id": "eo8kx60lOxPs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upload Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "from shutil import copy\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "copy(\"/content/drive/MyDrive/inference_test_cases.zip\", \"inference_test_cases.zip\")\n",
    "!unzip inference_test_cases.zip"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Inference"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from os import listdir\n",
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "from time import time\n",
    "\n",
    "\n",
    "def main():\n",
    "    CT_configuration = {\n",
    "    \"transpose_forward\": [\n",
    "        0,\n",
    "        1,\n",
    "        2\n",
    "    ],\n",
    "    \"spacing\": [\n",
    "        2.5,\n",
    "        0.7958984971046448,\n",
    "        0.7958984971046448\n",
    "    ],\n",
    "    'intensity_prop': {\n",
    "        \"max\": 3071.0,\n",
    "        \"mean\": 97.29716491699219,\n",
    "        \"median\": 118.0,\n",
    "        \"min\": -1024.0,\n",
    "        \"percentile_00_5\": -958.0,\n",
    "        \"percentile_99_5\": 270.0,\n",
    "        \"std\": 137.8484649658203\n",
    "    }}\n",
    "\n",
    "    normalization = CTNormalization(intensityproperties=CT_configuration['intensity_prop'])\n",
    "    cases = listdir(\"inference_test_cases\")\n",
    "    images, properties = SimpleITKIO().read_images([case[:case.find(\".\")] for case in cases])\n",
    "    results = {\"crop\": []}\n",
    "    for image in images:\n",
    "        data = image.astype(np.float32)\n",
    "        data = data.transpose([0, *[i + 1 for i in CT_configuration['transpose_forward']]])\n",
    "        original_spacing = [properties['spacing'][i] for i in CT_configuration['transpose_forward']]\n",
    "        t0 = time()\n",
    "        data, seg, bbox = crop_to_nonzero(data)\n",
    "        results[\"cropping\"].append(time() - t0)\n",
    "        target_spacing = CT_configuration['spacing']\n",
    "        if len(target_spacing) < len(data.shape[1:]):\n",
    "            target_spacing = [original_spacing[0]] + target_spacing\n",
    "        new_shape = compute_new_shape(data.shape[1:], original_spacing, target_spacing)\n",
    "        t0 = time()\n",
    "        data = normalization.run(data)\n",
    "        results[\"normalization\"].append(time() - t0)\n",
    "        resample_data_or_seg_to_shape(data, new_shape, original_spacing, target_spacing)\n",
    "        results[\"resampling\"].append(time() - t0)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ]
}
