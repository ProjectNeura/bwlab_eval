{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M74X2Bc2MWPN"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProjectNeura/bwlab_eval/blob/main/preprocess_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "M74X2Bc2MWPN"
      }
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ulizc2jCR3J",
        "outputId": "1b2e0f3d-4ffe-45a4-d01c-de2184194e66"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ED_Kk9awK-1N",
        "outputId": "5d44e8ec-596b-4947-a3f1-00b16e0812de"
      },
      "source": [
        "!pip3 install nnunetv2 acvl-utils"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnunetv2\n",
            "  Downloading nnunetv2-2.6.0.tar.gz (206 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/206.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.3/206.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting acvl-utils\n",
            "  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.6.0+cu124)\n",
            "Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2)\n",
            "  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (4.67.1)\n",
            "Collecting dicom2nifti (from nnunetv2)\n",
            "  Downloading dicom2nifti-2.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.14.1)\n",
            "Collecting batchgenerators>=0.25.1 (from nnunetv2)\n",
            "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.2)\n",
            "Collecting SimpleITK>=2.2.1 (from nnunetv2)\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.20.3)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.2.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.13.2)\n",
            "Collecting imagecodecs (from nnunetv2)\n",
            "  Downloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting yacs (from nnunetv2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting batchgeneratorsv2>=0.2 (from nnunetv2)\n",
            "  Downloading batchgeneratorsv2-0.2.3.tar.gz (35 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.8.1)\n",
            "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.2.0)\n",
            "Collecting connected-components-3d (from acvl-utils)\n",
            "  Downloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (11.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.0.0)\n",
            "Collecting unittest2 (from batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (3.6.0)\n",
            "Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.2->nnunetv2)\n",
            "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.1.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (4.3.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (2.10.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (9.0.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.37.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2) (1.3.0)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2)\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting python-gdcm (from dicom2nifti->nnunetv2)\n",
            "  Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2) (6.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2) (1.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (3.0.2)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dicom2nifti-2.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n",
            "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.6.0-py3-none-any.whl size=276977 sha256=56acb630536536779744b20a95e71fa1f2d9ab555f953587cb0e42846996ce9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/bb/f932cb0032d1aacc2f336de421448313d147db8eed671096e9\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27214 sha256=fa044ea113a4b36f5611cb6cbf802798f64cd2a4c9dbd43a9e9faa0fe20fee35\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=cbdc695dd54e6239d33bcab9ed8351958861ce9dd222aa0faae58a50a0658f8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/11/c7/fadca30e054c602093ffe36ba8a2f0a87dd2f86ac75191d3ed\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.2.3-py3-none-any.whl size=47526 sha256=830e0f6209e195b63492f3ce3b38fa580a485d2a704975ce701b680e3e9a8cf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/68/57/3a0eceb67b9c1b630df16113639b66a843dfd6686a4ed5ae1d\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30046 sha256=32a8072a09909eff139df992fbd22b8e1c50ed319520d8cf9491d5b3fa83be7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/8f/23/133ba252665b6f93abdbb294b323cc8fec041be83e4d22b701\n",
            "Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n",
            "Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, imagecodecs, connected-components-3d, unittest2, dicom2nifti, batchgenerators, fft-conv-pytorch, dynamic-network-architectures, acvl-utils, batchgeneratorsv2, nnunetv2\n",
            "Successfully installed SimpleITK-2.4.1 acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.2.3 connected-components-3d-3.23.0 dicom2nifti-2.5.1 dynamic-network-architectures-0.3.1 fft-conv-pytorch-1.2.0 imagecodecs-2024.12.30 linecache2-1.0.0 nnunetv2-2.6.0 pydicom-3.0.1 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "524c5829bd464f7d962207e5054d5f2a"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Functions"
      ],
      "metadata": {
        "id": "nck9mZmYOtvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import abstractmethod, ABC\n",
        "from collections import OrderedDict\n",
        "from copy import deepcopy\n",
        "from typing import Optional, Dict, Union, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from acvl_utils.cropping_and_padding.bounding_boxes import get_bbox_from_mask, bounding_box_to_slice\n",
        "from batchgenerators.augmentations.utils import resize_segmentation\n",
        "from nnunetv2.configuration import ANISO_THRESHOLD\n",
        "from scipy.ndimage import binary_fill_holes, map_coordinates\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "class ImageNormalization(ABC):\n",
        "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = None\n",
        "\n",
        "    def __init__(self, use_mask_for_norm: Optional[bool] = None, intensityproperties: Optional[Dict] = None,\n",
        "                 target_dtype: torch.dtype = torch.float32):\n",
        "        assert use_mask_for_norm is None or isinstance(use_mask_for_norm, bool)\n",
        "        self.use_mask_for_norm = use_mask_for_norm\n",
        "        assert isinstance(intensityproperties, dict) or intensityproperties is None\n",
        "        self.intensityproperties = intensityproperties\n",
        "        self.target_dtype = target_dtype\n",
        "\n",
        "    @abstractmethod\n",
        "    def run(self, image: torch.Tensor, seg: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class CTNormalization(ImageNormalization):\n",
        "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = False\n",
        "\n",
        "    def run(self, image: np.ndarray, seg: np.ndarray = None) -> np.ndarray:\n",
        "        assert self.intensityproperties is not None, \"CTNormalization requires intensity properties\"\n",
        "        mean_intensity = self.intensityproperties['mean']\n",
        "        std_intensity = self.intensityproperties['std']\n",
        "        lower_bound = self.intensityproperties['percentile_00_5']\n",
        "        upper_bound = self.intensityproperties['percentile_99_5']\n",
        "\n",
        "        image = image.astype(self.target_dtype, copy=False)\n",
        "        np.clip(image, lower_bound, upper_bound, out=image)\n",
        "        image -= mean_intensity\n",
        "        image /= max(std_intensity, 1e-8)\n",
        "        return image\n",
        "\n",
        "\n",
        "def create_nonzero_mask(data):\n",
        "    \"\"\"\n",
        "\n",
        "    :param data:\n",
        "    :return: the mask is True where the data is nonzero\n",
        "    \"\"\"\n",
        "    assert data.ndim in (3, 4), \"data must have shape (C, X, Y, Z) or shape (C, X, Y)\"\n",
        "    nonzero_mask = data[0] != 0\n",
        "    for c in range(1, data.shape[0]):\n",
        "        nonzero_mask |= data[c] != 0\n",
        "    return binary_fill_holes(nonzero_mask)\n",
        "\n",
        "\n",
        "def crop_to_nonzero(data, seg=None, nonzero_label=-1):\n",
        "    \"\"\"\n",
        "\n",
        "    :param data:\n",
        "    :param seg:\n",
        "    :param nonzero_label: this will be written into the segmentation map\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    nonzero_mask = create_nonzero_mask(data)\n",
        "    bbox = get_bbox_from_mask(nonzero_mask)\n",
        "    slicer = bounding_box_to_slice(bbox)\n",
        "    nonzero_mask = nonzero_mask[slicer][None]\n",
        "\n",
        "    slicer = (slice(None),) + slicer\n",
        "    data = data[slicer]\n",
        "    if seg is not None:\n",
        "        seg = seg[slicer]\n",
        "        seg[(seg == 0) & (~nonzero_mask)] = nonzero_label\n",
        "    else:\n",
        "        seg = np.where(nonzero_mask, np.int8(0), np.int8(nonzero_label))\n",
        "    return data, seg, bbox\n",
        "\n",
        "\n",
        "def get_do_separate_z(spacing: Union[Tuple[float, ...], List[float], np.ndarray], anisotropy_threshold=ANISO_THRESHOLD):\n",
        "    do_separate_z = (np.max(spacing) / np.min(spacing)) > anisotropy_threshold\n",
        "    return do_separate_z\n",
        "\n",
        "\n",
        "def get_lowres_axis(new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]):\n",
        "    axis = np.where(max(new_spacing) / np.array(new_spacing) == 1)[0]  # find which axis is anisotropic\n",
        "    return axis\n",
        "\n",
        "\n",
        "def determine_do_sep_z_and_axis(\n",
        "        force_separate_z: bool,\n",
        "        current_spacing,\n",
        "        new_spacing,\n",
        "        separate_z_anisotropy_threshold: float = ANISO_THRESHOLD) -> Tuple[bool, Union[int, None]]:\n",
        "    if force_separate_z is not None:\n",
        "        do_separate_z = force_separate_z\n",
        "        if force_separate_z:\n",
        "            axis = get_lowres_axis(current_spacing)\n",
        "        else:\n",
        "            axis = None\n",
        "    else:\n",
        "        if get_do_separate_z(current_spacing, separate_z_anisotropy_threshold):\n",
        "            do_separate_z = True\n",
        "            axis = get_lowres_axis(current_spacing)\n",
        "        elif get_do_separate_z(new_spacing, separate_z_anisotropy_threshold):\n",
        "            do_separate_z = True\n",
        "            axis = get_lowres_axis(new_spacing)\n",
        "        else:\n",
        "            do_separate_z = False\n",
        "            axis = None\n",
        "\n",
        "    if axis is not None:\n",
        "        if len(axis) == 3:\n",
        "            do_separate_z = False\n",
        "            axis = None\n",
        "        elif len(axis) == 2:\n",
        "            # this happens for spacings like (0.24, 1.25, 1.25) for example. In that case we do not want to resample\n",
        "            # separately in the out of plane axis\n",
        "            do_separate_z = False\n",
        "            axis = None\n",
        "        else:\n",
        "            axis = axis[0]\n",
        "    return do_separate_z, axis\n",
        "\n",
        "\n",
        "def resample_data_or_seg(data: np.ndarray, new_shape: Union[Tuple[float, ...], List[float], np.ndarray],\n",
        "                         is_seg: bool = False, axis: Union[None, int] = None, order: int = 3,\n",
        "                         do_separate_z: bool = False, order_z: int = 0, dtype_out=None):\n",
        "    \"\"\"\n",
        "    separate_z=True will resample with order 0 along z\n",
        "    :param data:\n",
        "    :param new_shape:\n",
        "    :param is_seg:\n",
        "    :param axis:\n",
        "    :param order:\n",
        "    :param do_separate_z:\n",
        "    :param order_z: only applies if do_separate_z is True\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    assert data.ndim == 4, \"data must be (c, x, y, z)\"\n",
        "    assert len(new_shape) == data.ndim - 1\n",
        "\n",
        "    if is_seg:\n",
        "        resize_fn = resize_segmentation\n",
        "        kwargs = OrderedDict()\n",
        "    else:\n",
        "        resize_fn = resize\n",
        "        kwargs = {'mode': 'edge', 'anti_aliasing': False}\n",
        "    shape = np.array(data[0].shape)\n",
        "    new_shape = np.array(new_shape)\n",
        "    if dtype_out is None:\n",
        "        dtype_out = data.dtype\n",
        "    reshaped_final = np.zeros((data.shape[0], *new_shape), dtype=dtype_out)\n",
        "    if np.any(shape != new_shape):\n",
        "        data = data.astype(float, copy=False)\n",
        "        if do_separate_z:\n",
        "            # print(\"separate z, order in z is\", order_z, \"order inplane is\", order)\n",
        "            assert axis is not None, 'If do_separate_z, we need to know what axis is anisotropic'\n",
        "            if axis == 0:\n",
        "                new_shape_2d = new_shape[1:]\n",
        "            elif axis == 1:\n",
        "                new_shape_2d = new_shape[[0, 2]]\n",
        "            else:\n",
        "                new_shape_2d = new_shape[:-1]\n",
        "\n",
        "            for c in range(data.shape[0]):\n",
        "                tmp = deepcopy(new_shape)\n",
        "                tmp[axis] = shape[axis]\n",
        "                reshaped_here = np.zeros(tmp)\n",
        "                for slice_id in range(shape[axis]):\n",
        "                    if axis == 0:\n",
        "                        reshaped_here[slice_id] = resize_fn(data[c, slice_id], new_shape_2d, order, **kwargs)\n",
        "                    elif axis == 1:\n",
        "                        reshaped_here[:, slice_id] = resize_fn(data[c, :, slice_id], new_shape_2d, order, **kwargs)\n",
        "                    else:\n",
        "                        reshaped_here[:, :, slice_id] = resize_fn(data[c, :, :, slice_id], new_shape_2d, order,\n",
        "                                                                  **kwargs)\n",
        "                if shape[axis] != new_shape[axis]:\n",
        "\n",
        "                    # The following few lines are blatantly copied and modified from sklearn's resize()\n",
        "                    rows, cols, dim = new_shape[0], new_shape[1], new_shape[2]\n",
        "                    orig_rows, orig_cols, orig_dim = reshaped_here.shape\n",
        "\n",
        "                    # align_corners=False\n",
        "                    row_scale = float(orig_rows) / rows\n",
        "                    col_scale = float(orig_cols) / cols\n",
        "                    dim_scale = float(orig_dim) / dim\n",
        "\n",
        "                    map_rows, map_cols, map_dims = np.mgrid[:rows, :cols, :dim]\n",
        "                    map_rows = row_scale * (map_rows + 0.5) - 0.5\n",
        "                    map_cols = col_scale * (map_cols + 0.5) - 0.5\n",
        "                    map_dims = dim_scale * (map_dims + 0.5) - 0.5\n",
        "\n",
        "                    coord_map = np.array([map_rows, map_cols, map_dims])\n",
        "                    if not is_seg or order_z == 0:\n",
        "                        reshaped_final[c] = map_coordinates(reshaped_here, coord_map, order=order_z, mode='nearest')[\n",
        "                            None]\n",
        "                    else:\n",
        "                        unique_labels = np.sort(pd.unique(reshaped_here.ravel()))  # np.unique(reshaped_data)\n",
        "                        for i, cl in enumerate(unique_labels):\n",
        "                            reshaped_final[c][np.round(\n",
        "                                map_coordinates((reshaped_here == cl).astype(float), coord_map, order=order_z,\n",
        "                                                mode='nearest')) > 0.5] = cl\n",
        "                else:\n",
        "                    reshaped_final[c] = reshaped_here\n",
        "        else:\n",
        "            # print(\"no separate z, order\", order)\n",
        "            for c in range(data.shape[0]):\n",
        "                reshaped_final[c] = resize_fn(data[c], new_shape, order, **kwargs)\n",
        "        return reshaped_final\n",
        "    else:\n",
        "        # print(\"no resampling necessary\")\n",
        "        return data\n",
        "\n",
        "\n",
        "def resample_data_or_seg_to_shape(data: Union[torch.Tensor, np.ndarray],\n",
        "                                  new_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
        "                                  current_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
        "                                  new_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
        "                                  is_seg: bool = False,\n",
        "                                  order: int = 3, order_z: int = 0,\n",
        "                                  force_separate_z: Union[bool, None] = False,\n",
        "                                  separate_z_anisotropy_threshold: float = ANISO_THRESHOLD):\n",
        "    \"\"\"\n",
        "    needed for segmentation export. Stupid, I know\n",
        "    \"\"\"\n",
        "    if isinstance(data, torch.Tensor):\n",
        "        data = data.numpy()\n",
        "\n",
        "    do_separate_z, axis = determine_do_sep_z_and_axis(force_separate_z, current_spacing, new_spacing,\n",
        "                                                      separate_z_anisotropy_threshold)\n",
        "\n",
        "    if data is not None:\n",
        "        assert data.ndim == 4, \"data must be c x y z\"\n",
        "\n",
        "    data_reshaped = resample_data_or_seg(data, new_shape, is_seg, axis, order, do_separate_z, order_z=order_z)\n",
        "    return data_reshaped\n",
        "\n",
        "\n",
        "def compute_new_shape(old_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
        "                      old_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
        "                      new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]) -> np.ndarray:\n",
        "    assert len(old_spacing) == len(old_shape)\n",
        "    assert len(old_shape) == len(new_spacing)\n",
        "    new_shape = np.array([int(round(i / j * k)) for i, j, k in zip(old_spacing, new_spacing, old_shape)])\n",
        "    return new_shape"
      ],
      "metadata": {
        "id": "eo8kx60lOxPs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKjALJgiCR3N"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload Data"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_G76A3pCR3O",
        "outputId": "251636e6-f657-4d07-f46f-3deff4b9a023"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  inference_test_cases.zip\n",
            " extracting: inference_test_cases/FLARETs_0001_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0015_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0018_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0036_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0046_0000.nii.gz  \n"
          ]
        }
      ],
      "execution_count": 7,
      "source": [
        "from google.colab import drive\n",
        "from os import mkdir\n",
        "from os.path import exists\n",
        "from shutil import copy\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "if not exists(\"inference_test_cases\"):\n",
        "    mkdir(\"inference_test_cases\")\n",
        "if not exists(\"inference_test_cases.zip\"):\n",
        "    copy(\"/content/drive/MyDrive/inference_test_cases.zip\", \"inference_test_cases.zip\")\n",
        "!unzip inference_test_cases.zip -d inference_test_cases"
      ]
    },
    {
      "metadata": {
        "id": "E6L4w8O7CR3O"
      },
      "cell_type": "markdown",
      "source": [
        "## Run Inference"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "ltDl7InDCR3O",
        "outputId": "dfda1886-e24e-465b-89af-244613466c98"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR! Not all input images have the same shape!\n",
            "Shapes:\n",
            "[(1, 105, 512, 512), (1, 512, 512, 512), (1, 299, 512, 512), (1, 406, 512, 512), (1, 203, 512, 512)]\n",
            "Image files:\n",
            "['FLARETs_0036_0000', 'FLARETs_0015_0000', 'FLARETs_0046_0000', 'FLARETs_0001_0000', 'FLARETs_0018_0000']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f2df568159ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-f2df568159ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnormalization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintensityproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCT_configuration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intensity_prop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inference_test_cases\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleITKIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"crop\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nnunetv2/imageio/simpleitk_reader_writer.py\u001b[0m in \u001b[0;36mread_images\u001b[0;34m(self, image_fnames)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image files:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_fnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_all_same\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspacings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR! Not all input images have the same spacing!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: "
          ]
        }
      ],
      "execution_count": 13,
      "source": [
        "from os import listdir\n",
        "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
        "from time import time\n",
        "\n",
        "\n",
        "def main():\n",
        "    CT_configuration = {\n",
        "    \"transpose_forward\": [\n",
        "        0,\n",
        "        1,\n",
        "        2\n",
        "    ],\n",
        "    \"spacing\": [\n",
        "        2.5,\n",
        "        0.7958984971046448,\n",
        "        0.7958984971046448\n",
        "    ],\n",
        "    'intensity_prop': {\n",
        "        \"max\": 3071.0,\n",
        "        \"mean\": 97.29716491699219,\n",
        "        \"median\": 118.0,\n",
        "        \"min\": -1024.0,\n",
        "        \"percentile_00_5\": -958.0,\n",
        "        \"percentile_99_5\": 270.0,\n",
        "        \"std\": 137.8484649658203\n",
        "    }}\n",
        "\n",
        "    normalization = CTNormalization(intensityproperties=CT_configuration['intensity_prop'])\n",
        "    cases = listdir(\"inference_test_cases\")\n",
        "    results = {\"crop\": []}\n",
        "    for case in cases:\n",
        "        image, properties = SimpleITKIO().read_images([case[:case.find(\".\")]])\n",
        "        data = image.astype(np.float32)\n",
        "        data = data.transpose([0, *[i + 1 for i in CT_configuration['transpose_forward']]])\n",
        "        original_spacing = [properties['spacing'][i] for i in CT_configuration['transpose_forward']]\n",
        "        t0 = time()\n",
        "        data, seg, bbox = crop_to_nonzero(data)\n",
        "        results[\"cropping\"].append(time() - t0)\n",
        "        target_spacing = CT_configuration['spacing']\n",
        "        if len(target_spacing) < len(data.shape[1:]):\n",
        "            target_spacing = [original_spacing[0]] + target_spacing\n",
        "        new_shape = compute_new_shape(data.shape[1:], original_spacing, target_spacing)\n",
        "        t0 = time()\n",
        "        data = normalization.run(data)\n",
        "        results[\"normalization\"].append(time() - t0)\n",
        "        resample_data_or_seg_to_shape(data, new_shape, original_spacing, target_spacing)\n",
        "        results[\"resampling\"].append(time() - t0)\n",
        "\n",
        "\n",
        "main()"
      ]
    }
  ]
}