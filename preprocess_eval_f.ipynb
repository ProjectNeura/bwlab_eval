{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install Dependencies",
   "id": "36fb3d2690aade1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip3 install nnunetv2 acvl-utils cupy-cuda12x",
   "id": "feebbc5d019069e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Functions",
   "id": "41c8492b64215436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from abc import abstractmethod, ABC\n",
    "from typing import Optional, Dict, Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from acvl_utils.cropping_and_padding.bounding_boxes import get_bbox_from_mask, bounding_box_to_slice\n",
    "from nnunetv2.configuration import ANISO_THRESHOLD\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "\n",
    "class ImageNormalization(ABC):\n",
    "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = None\n",
    "\n",
    "    def __init__(self, use_mask_for_norm: Optional[bool] = None, intensityproperties: Optional[Dict] = None,\n",
    "                 target_dtype: torch.dtype = torch.float32):\n",
    "        assert use_mask_for_norm is None or isinstance(use_mask_for_norm, bool)\n",
    "        self.use_mask_for_norm = use_mask_for_norm\n",
    "        assert isinstance(intensityproperties, dict) or intensityproperties is None\n",
    "        self.intensityproperties = intensityproperties\n",
    "        self.target_dtype = target_dtype\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, image: torch.Tensor, seg: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class CTNormalization(ImageNormalization):\n",
    "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = False\n",
    "\n",
    "    def run(self, image: torch.Tensor, seg: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        assert self.intensityproperties is not None, \"CTNormalization requires intensity properties\"\n",
    "        mean_intensity = self.intensityproperties['mean']\n",
    "        std_intensity = self.intensityproperties['std']\n",
    "        lower_bound = self.intensityproperties['percentile_00_5']\n",
    "        upper_bound = self.intensityproperties['percentile_99_5']\n",
    "\n",
    "        image = image.to(dtype=self.target_dtype)\n",
    "        image = torch.clamp(image, lower_bound, upper_bound)\n",
    "        image = (image - mean_intensity) / max(std_intensity, 1e-8)\n",
    "        return image\n",
    "\n",
    "\n",
    "def create_nonzero_mask(data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :return: the mask is True where the data is nonzero\n",
    "    \"\"\"\n",
    "    assert data.ndim in (3, 4), \"data must have shape (C, X, Y, Z) or shape (C, X, Y)\"\n",
    "    nonzero_mask = data[0] != 0\n",
    "    for c in range(1, data.shape[0]):\n",
    "        nonzero_mask |= data[c] != 0\n",
    "    return binary_fill_holes(nonzero_mask)\n",
    "\n",
    "\n",
    "def crop_to_nonzero(data, seg=None, nonzero_label=-1):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param seg:\n",
    "    :param nonzero_label: this will be written into the segmentation map\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nonzero_mask = create_nonzero_mask(data)\n",
    "    bbox = get_bbox_from_mask(nonzero_mask)\n",
    "    slicer = bounding_box_to_slice(bbox)\n",
    "    nonzero_mask = nonzero_mask[slicer][None]\n",
    "\n",
    "    slicer = (slice(None),) + slicer\n",
    "    data = data[slicer]\n",
    "    if seg is not None:\n",
    "        seg = seg[slicer]\n",
    "        seg[(seg == 0) & (~nonzero_mask)] = nonzero_label\n",
    "    else:\n",
    "        seg = np.where(nonzero_mask, np.int8(0), np.int8(nonzero_label))\n",
    "    return data, seg, bbox\n",
    "\n",
    "\n",
    "def compute_new_shape(old_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                      old_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                      new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]) -> np.ndarray:\n",
    "    assert len(old_spacing) == len(old_shape)\n",
    "    assert len(old_shape) == len(new_spacing)\n",
    "    new_shape = np.array([int(round(i / j * k)) for i, j, k in zip(old_spacing, new_spacing, old_shape)])\n",
    "    return new_shape\n",
    "\n",
    "\n",
    "def fast_resample_data_or_seg_to_shape(data: Union[torch.Tensor, np.ndarray],\n",
    "                                       new_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                                       current_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                       new_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                       is_seg: bool = False,\n",
    "                                       order: int = 3, order_z: int = 0,\n",
    "                                       force_separate_z: Union[bool, None] = False,\n",
    "                                       separate_z_anisotropy_threshold: float = ANISO_THRESHOLD):\n",
    "    use_gpu = True\n",
    "    device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "    order_to_mode_map = {\n",
    "        0: \"nearest\",\n",
    "        1: \"trilinear\" if new_shape[0] > 1 else \"bilinear\",\n",
    "        2: \"trilinear\" if new_shape[0] > 1 else \"bilinear\",\n",
    "        3: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "        4: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "        5: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "    }\n",
    "    resize_fn = torch.nn.functional.interpolate\n",
    "    kwargs = {\n",
    "        'mode': order_to_mode_map[order],\n",
    "        'align_corners': False\n",
    "    }\n",
    "    shape = np.array(data[0].shape)\n",
    "    new_shape = np.array(new_shape)\n",
    "    if np.any(shape != new_shape):\n",
    "        if not isinstance(data, torch.Tensor):\n",
    "            #torch_data = torch.from_numpy(data).float()\n",
    "            torch_data = torch.as_tensor(data.get())\n",
    "        else:\n",
    "            torch_data = data.float()\n",
    "        if new_shape[0] == 1:\n",
    "            torch_data = torch_data.transpose(1, 0)\n",
    "            new_shape = new_shape[1:]\n",
    "        else:\n",
    "            torch_data = torch_data.unsqueeze(0)\n",
    "\n",
    "        torch_data = resize_fn(torch_data.to(device), tuple(new_shape), **kwargs)\n",
    "\n",
    "        if new_shape[0] == 1:\n",
    "            torch_data = torch_data.transpose(1, 0)\n",
    "        else:\n",
    "            torch_data = torch_data.squeeze(0)\n",
    "\n",
    "        # if use_gpu:\n",
    "        #     torch_data = torch_data.cpu()\n",
    "        reshaped_final_data = torch_data\n",
    "        # if isinstance(data, np.ndarray):\n",
    "        #     reshaped_final_data = torch_data.numpy().astype(dtype_data)\n",
    "        # else:\n",
    "        #     reshaped_final_data = torch_data.to(dtype_data)\n",
    "\n",
    "        #print(f\"Reshaped data from {shape} to {new_shape}\")\n",
    "        #print(f\"reshaped_final_data shape: {reshaped_final_data.shape}\")\n",
    "        assert reshaped_final_data.ndim == 4, f\"reshaped_final_data.shape = {reshaped_final_data.shape}\"\n",
    "        return reshaped_final_data\n",
    "    else:\n",
    "        print(\"no resampling necessary\")\n",
    "        return data"
   ],
   "id": "f903ce2dc6a8c980"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upload Data",
   "id": "f71dbe0e5caa1e99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "from os import mkdir\n",
    "from os.path import exists\n",
    "from shutil import copy\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "if not exists(\"inference_test_cases\"):\n",
    "    mkdir(\"inference_test_cases\")\n",
    "if not exists(\"inference_test_cases.zip\"):\n",
    "    copy(\"/content/drive/MyDrive/inference_test_cases.zip\", \"inference_test_cases.zip\")\n",
    "!unzip inference_test_cases.zip -d inference_test_cases"
   ],
   "id": "368d347daebbbe43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Inference",
   "id": "7dabdbac5071b697"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from os import listdir\n",
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "from time import time\n",
    "\n",
    "\n",
    "def main() -> dict[str, list[float]]:\n",
    "    CT_configuration = {\n",
    "        \"transpose_forward\": [\n",
    "            0,\n",
    "            1,\n",
    "            2\n",
    "        ],\n",
    "        \"spacing\": [\n",
    "            2.5,\n",
    "            0.7958984971046448,\n",
    "            0.7958984971046448\n",
    "        ],\n",
    "        'intensity_prop': {\n",
    "            \"max\": 3071.0,\n",
    "            \"mean\": 97.29716491699219,\n",
    "            \"median\": 118.0,\n",
    "            \"min\": -1024.0,\n",
    "            \"percentile_00_5\": -958.0,\n",
    "            \"percentile_99_5\": 270.0,\n",
    "            \"std\": 137.8484649658203\n",
    "        }\n",
    "    }\n",
    "\n",
    "    normalization = CTNormalization(intensityproperties=CT_configuration['intensity_prop'])\n",
    "    cases = listdir(\"inference_test_cases\")\n",
    "    results = {\"cropping\": [], \"normalization\": [], \"resampling\": []}\n",
    "    for case in cases:\n",
    "        image, properties = SimpleITKIO().read_images([case[:case.find(\".\")]])\n",
    "        image = torch.from_numpy(image).to(dtype=torch.float32, memory_format=torch.contiguous_format).to('cuda')\n",
    "        data = image.clone()\n",
    "        data = data.permute([0, *[i + 1 for i in CT_configuration['transpose_forward']]])\n",
    "        original_spacing = [properties['spacing'][i] for i in CT_configuration['transpose_forward']]\n",
    "        t0 = time()\n",
    "        data, seg, bbox = crop_to_nonzero(data)\n",
    "        torch.cuda.synchronize()\n",
    "        results[\"cropping\"].append(time() - t0)\n",
    "        target_spacing = CT_configuration['spacing']\n",
    "        if len(target_spacing) < len(data.shape[1:]):\n",
    "            target_spacing = [original_spacing[0]] + target_spacing\n",
    "        new_shape = compute_new_shape(data.shape[1:], original_spacing, target_spacing)\n",
    "        t0 = time()\n",
    "        data = normalization.run(data)\n",
    "        torch.cuda.synchronize()\n",
    "        results[\"normalization\"].append(time() - t0)\n",
    "        fast_resample_data_or_seg_to_shape(data, new_shape, original_spacing, target_spacing)\n",
    "        torch.cuda.synchronize()\n",
    "        results[\"resampling\"].append(time() - t0)\n",
    "    return results\n",
    "\n",
    "\n",
    "print(main())"
   ],
   "id": "88ee2ea0f7d1e5a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
