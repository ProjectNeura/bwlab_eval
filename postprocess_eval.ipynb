{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "< a\n",
    "href = \"https://colab.research.google.com/github/ProjectNeura/bwlab_eval/blob/main/preprocess_eval.ipynb\"\n",
    "target = \"_parent\" > < img\n",
    "src = \"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "alt = \"Open In Colab\" / > </ a >"
   ],
   "id": "1c1883dd88517f96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install Dependencies",
   "id": "a215e1be9059ecb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126",
   "id": "2d5862f235b196e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip3 install nnunetv2 acvl-utils",
   "id": "abd5ed81daaee8f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Functions",
   "id": "e12931d79bd29de2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from typing import Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from batchgenerators.augmentations.utils import resize_segmentation\n",
    "from nnunetv2.configuration import ANISO_THRESHOLD\n",
    "from scipy.ndimage import map_coordinates\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "def get_do_separate_z(spacing: Union[Tuple[float, ...], List[float], np.ndarray], anisotropy_threshold=ANISO_THRESHOLD):\n",
    "    do_separate_z = (np.max(spacing) / np.min(spacing)) > anisotropy_threshold\n",
    "    return do_separate_z\n",
    "\n",
    "\n",
    "def get_lowres_axis(new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]):\n",
    "    axis = np.where(max(new_spacing) / np.array(new_spacing) == 1)[0]  # find which axis is anisotropic\n",
    "    return axis\n",
    "\n",
    "\n",
    "def determine_do_sep_z_and_axis(\n",
    "        force_separate_z: bool,\n",
    "        current_spacing,\n",
    "        new_spacing,\n",
    "        separate_z_anisotropy_threshold: float = ANISO_THRESHOLD) -> Tuple[bool, Union[int, None]]:\n",
    "    if force_separate_z is not None:\n",
    "        do_separate_z = force_separate_z\n",
    "        if force_separate_z:\n",
    "            axis = get_lowres_axis(current_spacing)\n",
    "        else:\n",
    "            axis = None\n",
    "    else:\n",
    "        if get_do_separate_z(current_spacing, separate_z_anisotropy_threshold):\n",
    "            do_separate_z = True\n",
    "            axis = get_lowres_axis(current_spacing)\n",
    "        elif get_do_separate_z(new_spacing, separate_z_anisotropy_threshold):\n",
    "            do_separate_z = True\n",
    "            axis = get_lowres_axis(new_spacing)\n",
    "        else:\n",
    "            do_separate_z = False\n",
    "            axis = None\n",
    "\n",
    "    if axis is not None:\n",
    "        if len(axis) == 3:\n",
    "            do_separate_z = False\n",
    "            axis = None\n",
    "        elif len(axis) == 2:\n",
    "            # this happens for spacings like (0.24, 1.25, 1.25) for example. In that case we do not want to resample\n",
    "            # separately in the out of plane axis\n",
    "            do_separate_z = False\n",
    "            axis = None\n",
    "        else:\n",
    "            axis = axis[0]\n",
    "    return do_separate_z, axis\n",
    "\n",
    "\n",
    "def resample_data_or_seg(data: np.ndarray, new_shape: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                         is_seg: bool = False, axis: Union[None, int] = None, order: int = 3,\n",
    "                         do_separate_z: bool = False, order_z: int = 0, dtype_out=None):\n",
    "    \"\"\"\n",
    "    separate_z=True will resample with order 0 along z\n",
    "    :param data:\n",
    "    :param new_shape:\n",
    "    :param is_seg:\n",
    "    :param axis:\n",
    "    :param order:\n",
    "    :param do_separate_z:\n",
    "    :param order_z: only applies if do_separate_z is True\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert data.ndim == 4, \"data must be (c, x, y, z)\"\n",
    "    assert len(new_shape) == data.ndim - 1\n",
    "\n",
    "    if is_seg:\n",
    "        resize_fn = resize_segmentation\n",
    "        kwargs = OrderedDict()\n",
    "    else:\n",
    "        resize_fn = resize\n",
    "        kwargs = {'mode': 'edge', 'anti_aliasing': False}\n",
    "    shape = np.array(data[0].shape)\n",
    "    new_shape = np.array(new_shape)\n",
    "    if dtype_out is None:\n",
    "        dtype_out = data.dtype\n",
    "    reshaped_final = np.zeros((data.shape[0], *new_shape), dtype=dtype_out)\n",
    "    if np.any(shape != new_shape):\n",
    "        data = data.astype(float, copy=False)\n",
    "        if do_separate_z:\n",
    "            # print(\"separate z, order in z is\", order_z, \"order inplane is\", order)\n",
    "            assert axis is not None, 'If do_separate_z, we need to know what axis is anisotropic'\n",
    "            if axis == 0:\n",
    "                new_shape_2d = new_shape[1:]\n",
    "            elif axis == 1:\n",
    "                new_shape_2d = new_shape[[0, 2]]\n",
    "            else:\n",
    "                new_shape_2d = new_shape[:-1]\n",
    "\n",
    "            for c in range(data.shape[0]):\n",
    "                tmp = deepcopy(new_shape)\n",
    "                tmp[axis] = shape[axis]\n",
    "                reshaped_here = np.zeros(tmp)\n",
    "                for slice_id in range(shape[axis]):\n",
    "                    if axis == 0:\n",
    "                        reshaped_here[slice_id] = resize_fn(data[c, slice_id], new_shape_2d, order, **kwargs)\n",
    "                    elif axis == 1:\n",
    "                        reshaped_here[:, slice_id] = resize_fn(data[c, :, slice_id], new_shape_2d, order, **kwargs)\n",
    "                    else:\n",
    "                        reshaped_here[:, :, slice_id] = resize_fn(data[c, :, :, slice_id], new_shape_2d, order,\n",
    "                                                                  **kwargs)\n",
    "                if shape[axis] != new_shape[axis]:\n",
    "\n",
    "                    # The following few lines are blatantly copied and modified from sklearn's resize()\n",
    "                    rows, cols, dim = new_shape[0], new_shape[1], new_shape[2]\n",
    "                    orig_rows, orig_cols, orig_dim = reshaped_here.shape\n",
    "\n",
    "                    # align_corners=False\n",
    "                    row_scale = float(orig_rows) / rows\n",
    "                    col_scale = float(orig_cols) / cols\n",
    "                    dim_scale = float(orig_dim) / dim\n",
    "\n",
    "                    map_rows, map_cols, map_dims = np.mgrid[:rows, :cols, :dim]\n",
    "                    map_rows = row_scale * (map_rows + 0.5) - 0.5\n",
    "                    map_cols = col_scale * (map_cols + 0.5) - 0.5\n",
    "                    map_dims = dim_scale * (map_dims + 0.5) - 0.5\n",
    "\n",
    "                    coord_map = np.array([map_rows, map_cols, map_dims])\n",
    "                    if not is_seg or order_z == 0:\n",
    "                        reshaped_final[c] = map_coordinates(reshaped_here, coord_map, order=order_z, mode='nearest')[\n",
    "                            None]\n",
    "                    else:\n",
    "                        unique_labels = np.sort(pd.unique(reshaped_here.ravel()))  # np.unique(reshaped_data)\n",
    "                        for i, cl in enumerate(unique_labels):\n",
    "                            reshaped_final[c][np.round(\n",
    "                                map_coordinates((reshaped_here == cl).astype(float), coord_map, order=order_z,\n",
    "                                                mode='nearest')) > 0.5] = cl\n",
    "                else:\n",
    "                    reshaped_final[c] = reshaped_here\n",
    "        else:\n",
    "            # print(\"no separate z, order\", order)\n",
    "            for c in range(data.shape[0]):\n",
    "                reshaped_final[c] = resize_fn(data[c], new_shape, order, **kwargs)\n",
    "        return reshaped_final\n",
    "    else:\n",
    "        # print(\"no resampling necessary\")\n",
    "        return data\n",
    "\n",
    "\n",
    "def resample_data_or_seg_to_shape(data: Union[torch.Tensor, np.ndarray],\n",
    "                                  new_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                                  current_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                  new_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                  is_seg: bool = False,\n",
    "                                  order: int = 3, order_z: int = 0,\n",
    "                                  force_separate_z: Union[bool, None] = False,\n",
    "                                  separate_z_anisotropy_threshold: float = ANISO_THRESHOLD):\n",
    "    \"\"\"\n",
    "    needed for segmentation export. Stupid, I know\n",
    "    \"\"\"\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.numpy()\n",
    "\n",
    "    do_separate_z, axis = determine_do_sep_z_and_axis(force_separate_z, current_spacing, new_spacing,\n",
    "                                                      separate_z_anisotropy_threshold)\n",
    "\n",
    "    if data is not None:\n",
    "        assert data.ndim == 4, \"data must be c x y z\"\n",
    "\n",
    "    data_reshaped = resample_data_or_seg(data, new_shape, is_seg, axis, order, do_separate_z, order_z=order_z)\n",
    "    return data_reshaped\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def convert_probabilities_to_segmentation(predicted_probabilities: Union[np.ndarray, torch.Tensor]) -> \\\n",
    "        Union[np.ndarray, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    assumes that inference_nonlinearity was already applied!\n",
    "\n",
    "    predicted_probabilities has to have shape (c, x, y(, z)) where c is the number of classes/regions\n",
    "    \"\"\"\n",
    "    if not isinstance(predicted_probabilities, (np.ndarray, torch.Tensor)):\n",
    "        raise RuntimeError(f\"Unexpected input type. Expected np.ndarray or torch.Tensor,\"\n",
    "                           f\" got {type(predicted_probabilities)}\")\n",
    "\n",
    "    # numpy is faster than torch. :facepalm:\n",
    "    is_numpy = isinstance(predicted_probabilities, np.ndarray)\n",
    "    if not is_numpy:\n",
    "        predicted_probabilities = predicted_probabilities.numpy()\n",
    "    segmentation = predicted_probabilities.argmax(0)\n",
    "    if not is_numpy:\n",
    "        segmentation = torch.from_numpy(segmentation)\n",
    "\n",
    "    return segmentation\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def convert_logits_to_segmentation(predicted_logits: Union[np.ndarray, torch.Tensor]) -> \\\n",
    "        Union[np.ndarray, torch.Tensor]:\n",
    "    input_is_numpy = isinstance(predicted_logits, np.ndarray)\n",
    "    # we can skip this step if we do not have region. Argmax is the same between logits or probabilities\n",
    "\n",
    "    probabilities = predicted_logits\n",
    "    if input_is_numpy and isinstance(probabilities, torch.Tensor):\n",
    "        probabilities = probabilities.cpu().numpy()\n",
    "    return convert_probabilities_to_segmentation(probabilities)"
   ],
   "id": "b1c42717a8d68762"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upload Data",
   "id": "3be34e2dfff55842"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "from os import mkdir\n",
    "from os.path import exists\n",
    "from shutil import copy\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "!rm -r inference_test_cases\n",
    "mkdir(\"inference_test_cases\")\n",
    "if not exists(\"inference_test_cases.zip\"):\n",
    "    copy(\"/content/drive/MyDrive/inference_test_cases.zip\", \"inference_test_cases.zip\")\n",
    "!unzip inference_test_cases.zip -d inference_test_cases"
   ],
   "id": "cef79d9ad91f482d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Inference",
   "id": "752549d5b4d2dbc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from os import listdir\n",
    "from time import time\n",
    "from torch import load\n",
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "\n",
    "\n",
    "def main() -> dict[str, list[float]]:\n",
    "    CT_configuration = {\n",
    "        \"transpose_forward\": [\n",
    "            0,\n",
    "            1,\n",
    "            2\n",
    "        ],\n",
    "        \"spacing\": [\n",
    "            2.5,\n",
    "            0.7958984971046448,\n",
    "            0.7958984971046448\n",
    "        ],\n",
    "        'intensity_prop': {\n",
    "            \"max\": 3071.0,\n",
    "            \"mean\": 97.29716491699219,\n",
    "            \"median\": 118.0,\n",
    "            \"min\": -1024.0,\n",
    "            \"percentile_00_5\": -958.0,\n",
    "            \"percentile_99_5\": 270.0,\n",
    "            \"std\": 137.8484649658203\n",
    "        }}\n",
    "\n",
    "    cases = listdir(\"inference_test_cases\")\n",
    "    results = {\"resampling\": [], \"conversion\": []}\n",
    "    for case in cases:\n",
    "        image, properties = SimpleITKIO().read_images([f\"inference_test_cases/{case[:case.find('.')]}\"])\n",
    "        logit = load(f\"inference_test_logit/{case[:case.find('.')]}\").numpy()\n",
    "        spacing_transposed = [properties['spacing'][i] for i in CT_configuration['transpose_forward']]\n",
    "        current_spacing = CT_configuration['spacing'] if len(CT_configuration['spacing']) == len(\n",
    "            properties['shape_after_cropping_and_before_resampling']) else [spacing_transposed[0],\n",
    "                                                                            *CT_configuration['spacing']]\n",
    "        t0 = time()\n",
    "        predicted_logit = resample_data_or_seg_to_shape(logit, properties['shape_after_cropping_and_before_resampling'],\n",
    "                                                        current_spacing, [properties['spacing'][i] for i in\n",
    "                                                                          CT_configuration['transpose_forward']])\n",
    "        results[\"resampling\"].append(time() - t0)\n",
    "        t0 = time()\n",
    "        convert_logits_to_segmentation(predicted_logit)\n",
    "        results[\"conversion\"].append(time() - t0)\n",
    "    return results\n",
    "\n",
    "\n",
    "def add_up(table: dict[str, list[float]], entry: str, n: int, num_cases: int) -> list[float]:\n",
    "    r = []\n",
    "    for i in range(num_cases):\n",
    "        s = 0\n",
    "        for j in range(n):\n",
    "            s += table[entry][i + j * num_cases]\n",
    "        r.append(s / n)\n",
    "    return r\n",
    "\n",
    "\n",
    "_final = {\"resampling\": [], \"conversion\": []}\n",
    "_n = 10\n",
    "_num_cases = 5\n",
    "for _b in range(_n):\n",
    "    print(f\"Porcessing batch {_b}\")\n",
    "    _r = main()\n",
    "    _final[\"resampling\"] += _r[\"resampling\"]\n",
    "    _final[\"conversion\"] += _r[\"conversion\"]\n",
    "print(add_up(_final, \"resampling\", _n, _num_cases))\n",
    "print(add_up(_final, \"conversion\", _n, _num_cases))"
   ],
   "id": "aa5698861a6dce29"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
