{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M74X2Bc2MWPN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProjectNeura/bwlab_eval/blob/main/postprocess_eval_s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "M74X2Bc2MWPN"
      }
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ulizc2jCR3J",
        "outputId": "5e0d623e-22ad-4ff5-b1e1-62b7b9db6733"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ED_Kk9awK-1N",
        "outputId": "82f3203f-ce86-498a-c648-4d85e9711f2a"
      },
      "source": [
        "!pip3 install nnunetv2 acvl-utils"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnunetv2\n",
            "  Downloading nnunetv2-2.6.0.tar.gz (206 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/206.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.3/206.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting acvl-utils\n",
            "  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.6.0+cu124)\n",
            "Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2)\n",
            "  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (4.67.1)\n",
            "Collecting dicom2nifti (from nnunetv2)\n",
            "  Downloading dicom2nifti-2.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.14.1)\n",
            "Collecting batchgenerators>=0.25.1 (from nnunetv2)\n",
            "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.2)\n",
            "Collecting SimpleITK>=2.2.1 (from nnunetv2)\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.20.3)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.3.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.13.2)\n",
            "Collecting imagecodecs (from nnunetv2)\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting yacs (from nnunetv2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting batchgeneratorsv2>=0.2 (from nnunetv2)\n",
            "  Downloading batchgeneratorsv2-0.2.3.tar.gz (35 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.8.1)\n",
            "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.2.1)\n",
            "Collecting connected-components-3d (from acvl-utils)\n",
            "  Downloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (11.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.0.0)\n",
            "Collecting unittest2 (from batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (3.6.0)\n",
            "Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.2->nnunetv2)\n",
            "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.1.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (4.3.7)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (2.10.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (9.0.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.37.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (4.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2) (1.3.0)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2)\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting python-gdcm (from dicom2nifti->nnunetv2)\n",
            "  Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2) (6.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2) (1.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (3.0.2)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dicom2nifti-2.6.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n",
            "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.6.0-py3-none-any.whl size=277014 sha256=d5f79271db5a99b50da028ba9595f6d18f7f36d268c3bf4725af912779115139\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/bb/f932cb0032d1aacc2f336de421448313d147db8eed671096e9\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27213 sha256=87689ed5ced202aad6073b550b20a42b6e014e217085d4fe92b23f9b3f617d69\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=958284679109387ee2ebf1ed939871033e8662cea1e37a2e836b9df3a10ddc4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/11/c7/fadca30e054c602093ffe36ba8a2f0a87dd2f86ac75191d3ed\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.2.3-py3-none-any.whl size=47567 sha256=b1a23b7c40569887852ee1e274fa84c0edffc6f27398a2720d11ba572bc6b2a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/68/57/3a0eceb67b9c1b630df16113639b66a843dfd6686a4ed5ae1d\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30048 sha256=42a93b3c415cb0546690128551f256aebc4e841e78029f43662f9ffff1182b09\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/8f/23/133ba252665b6f93abdbb294b323cc8fec041be83e4d22b701\n",
            "Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n",
            "Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, imagecodecs, connected-components-3d, unittest2, dicom2nifti, batchgenerators, fft-conv-pytorch, dynamic-network-architectures, acvl-utils, batchgeneratorsv2, nnunetv2\n",
            "Successfully installed SimpleITK-2.4.1 acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.2.3 connected-components-3d-3.23.0 dicom2nifti-2.6.0 dynamic-network-architectures-0.3.1 fft-conv-pytorch-1.2.0 imagecodecs-2025.3.30 linecache2-1.0.0 nnunetv2-2.6.0 pydicom-3.0.1 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "6f316745b1c4430c8b667e83c8efed34"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Functions"
      ],
      "metadata": {
        "id": "nck9mZmYOtvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from copy import deepcopy\n",
        "from typing import Union, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from batchgenerators.augmentations.utils import resize_segmentation\n",
        "from nnunetv2.configuration import ANISO_THRESHOLD\n",
        "from scipy.ndimage import map_coordinates\n",
        "from scipy.ndimage import binary_fill_holes\n",
        "from acvl_utils.cropping_and_padding.bounding_boxes import get_bbox_from_mask, bounding_box_to_slice\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "def create_nonzero_mask(data):\n",
        "    \"\"\"\n",
        "\n",
        "    :param data:\n",
        "    :return: the mask is True where the data is nonzero\n",
        "    \"\"\"\n",
        "    assert data.ndim in (3, 4), \"data must have shape (C, X, Y, Z) or shape (C, X, Y)\"\n",
        "    nonzero_mask = data[0] != 0\n",
        "    for c in range(1, data.shape[0]):\n",
        "        nonzero_mask |= data[c] != 0\n",
        "    return binary_fill_holes(nonzero_mask)\n",
        "\n",
        "\n",
        "def crop_to_nonzero(data, seg=None, nonzero_label=-1):\n",
        "    \"\"\"\n",
        "\n",
        "    :param data:\n",
        "    :param seg:\n",
        "    :param nonzero_label: this will be written into the segmentation map\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    nonzero_mask = create_nonzero_mask(data)\n",
        "    bbox = get_bbox_from_mask(nonzero_mask)\n",
        "    slicer = bounding_box_to_slice(bbox)\n",
        "    nonzero_mask = nonzero_mask[slicer][None]\n",
        "\n",
        "    slicer = (slice(None), ) + slicer\n",
        "    data = data[slicer]\n",
        "    if seg is not None:\n",
        "        seg = seg[slicer]\n",
        "        seg[(seg == 0) & (~nonzero_mask)] = nonzero_label\n",
        "    else:\n",
        "        seg = np.where(nonzero_mask, np.int8(0), np.int8(nonzero_label))\n",
        "    return data, seg, bbox\n",
        "\n",
        "\n",
        "def get_do_separate_z(spacing: Union[Tuple[float, ...], List[float], np.ndarray], anisotropy_threshold=ANISO_THRESHOLD):\n",
        "    do_separate_z = (np.max(spacing) / np.min(spacing)) > anisotropy_threshold\n",
        "    return do_separate_z\n",
        "\n",
        "\n",
        "def get_lowres_axis(new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]):\n",
        "    axis = np.where(max(new_spacing) / np.array(new_spacing) == 1)[0]  # find which axis is anisotropic\n",
        "    return axis\n",
        "\n",
        "\n",
        "def determine_do_sep_z_and_axis(\n",
        "        force_separate_z: bool,\n",
        "        current_spacing,\n",
        "        new_spacing,\n",
        "        separate_z_anisotropy_threshold: float = ANISO_THRESHOLD) -> Tuple[bool, Union[int, None]]:\n",
        "    if force_separate_z is not None:\n",
        "        do_separate_z = force_separate_z\n",
        "        if force_separate_z:\n",
        "            axis = get_lowres_axis(current_spacing)\n",
        "        else:\n",
        "            axis = None\n",
        "    else:\n",
        "        if get_do_separate_z(current_spacing, separate_z_anisotropy_threshold):\n",
        "            do_separate_z = True\n",
        "            axis = get_lowres_axis(current_spacing)\n",
        "        elif get_do_separate_z(new_spacing, separate_z_anisotropy_threshold):\n",
        "            do_separate_z = True\n",
        "            axis = get_lowres_axis(new_spacing)\n",
        "        else:\n",
        "            do_separate_z = False\n",
        "            axis = None\n",
        "\n",
        "    if axis is not None:\n",
        "        if len(axis) == 3:\n",
        "            do_separate_z = False\n",
        "            axis = None\n",
        "        elif len(axis) == 2:\n",
        "            # this happens for spacings like (0.24, 1.25, 1.25) for example. In that case we do not want to resample\n",
        "            # separately in the out of plane axis\n",
        "            do_separate_z = False\n",
        "            axis = None\n",
        "        else:\n",
        "            axis = axis[0]\n",
        "    return do_separate_z, axis\n",
        "\n",
        "\n",
        "def resample_data_or_seg(data: np.ndarray, new_shape: Union[Tuple[float, ...], List[float], np.ndarray],\n",
        "                         is_seg: bool = False, axis: Union[None, int] = None, order: int = 3,\n",
        "                         do_separate_z: bool = False, order_z: int = 0, dtype_out=None):\n",
        "    \"\"\"\n",
        "    separate_z=True will resample with order 0 along z\n",
        "    :param data:\n",
        "    :param new_shape:\n",
        "    :param is_seg:\n",
        "    :param axis:\n",
        "    :param order:\n",
        "    :param do_separate_z:\n",
        "    :param order_z: only applies if do_separate_z is True\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    assert data.ndim == 4, \"data must be (c, x, y, z)\"\n",
        "    assert len(new_shape) == data.ndim - 1\n",
        "\n",
        "    if is_seg:\n",
        "        resize_fn = resize_segmentation\n",
        "        kwargs = OrderedDict()\n",
        "    else:\n",
        "        resize_fn = resize\n",
        "        kwargs = {'mode': 'edge', 'anti_aliasing': False}\n",
        "    shape = np.array(data[0].shape)\n",
        "    new_shape = np.array(new_shape)\n",
        "    if dtype_out is None:\n",
        "        dtype_out = data.dtype\n",
        "    reshaped_final = np.zeros((data.shape[0], *new_shape), dtype=dtype_out)\n",
        "    if np.any(shape != new_shape):\n",
        "        data = data.astype(float, copy=False)\n",
        "        if do_separate_z:\n",
        "            # print(\"separate z, order in z is\", order_z, \"order inplane is\", order)\n",
        "            assert axis is not None, 'If do_separate_z, we need to know what axis is anisotropic'\n",
        "            if axis == 0:\n",
        "                new_shape_2d = new_shape[1:]\n",
        "            elif axis == 1:\n",
        "                new_shape_2d = new_shape[[0, 2]]\n",
        "            else:\n",
        "                new_shape_2d = new_shape[:-1]\n",
        "\n",
        "            for c in range(data.shape[0]):\n",
        "                tmp = deepcopy(new_shape)\n",
        "                tmp[axis] = shape[axis]\n",
        "                reshaped_here = np.zeros(tmp)\n",
        "                for slice_id in range(shape[axis]):\n",
        "                    if axis == 0:\n",
        "                        reshaped_here[slice_id] = resize_fn(data[c, slice_id], new_shape_2d, order, **kwargs)\n",
        "                    elif axis == 1:\n",
        "                        reshaped_here[:, slice_id] = resize_fn(data[c, :, slice_id], new_shape_2d, order, **kwargs)\n",
        "                    else:\n",
        "                        reshaped_here[:, :, slice_id] = resize_fn(data[c, :, :, slice_id], new_shape_2d, order,\n",
        "                                                                  **kwargs)\n",
        "                if shape[axis] != new_shape[axis]:\n",
        "\n",
        "                    # The following few lines are blatantly copied and modified from sklearn's resize()\n",
        "                    rows, cols, dim = new_shape[0], new_shape[1], new_shape[2]\n",
        "                    orig_rows, orig_cols, orig_dim = reshaped_here.shape\n",
        "\n",
        "                    # align_corners=False\n",
        "                    row_scale = float(orig_rows) / rows\n",
        "                    col_scale = float(orig_cols) / cols\n",
        "                    dim_scale = float(orig_dim) / dim\n",
        "\n",
        "                    map_rows, map_cols, map_dims = np.mgrid[:rows, :cols, :dim]\n",
        "                    map_rows = row_scale * (map_rows + 0.5) - 0.5\n",
        "                    map_cols = col_scale * (map_cols + 0.5) - 0.5\n",
        "                    map_dims = dim_scale * (map_dims + 0.5) - 0.5\n",
        "\n",
        "                    coord_map = np.array([map_rows, map_cols, map_dims])\n",
        "                    if not is_seg or order_z == 0:\n",
        "                        reshaped_final[c] = map_coordinates(reshaped_here, coord_map, order=order_z, mode='nearest')[\n",
        "                            None]\n",
        "                    else:\n",
        "                        unique_labels = np.sort(pd.unique(reshaped_here.ravel()))  # np.unique(reshaped_data)\n",
        "                        for i, cl in enumerate(unique_labels):\n",
        "                            reshaped_final[c][np.round(\n",
        "                                map_coordinates((reshaped_here == cl).astype(float), coord_map, order=order_z,\n",
        "                                                mode='nearest')) > 0.5] = cl\n",
        "                else:\n",
        "                    reshaped_final[c] = reshaped_here\n",
        "        else:\n",
        "            # print(\"no separate z, order\", order)\n",
        "            for c in range(data.shape[0]):\n",
        "                reshaped_final[c] = resize_fn(data[c], new_shape, order, **kwargs)\n",
        "        return reshaped_final\n",
        "    else:\n",
        "        # print(\"no resampling necessary\")\n",
        "        return data\n",
        "\n",
        "\n",
        "def resample_data_or_seg_to_shape(data: Union[torch.Tensor, np.ndarray],\n",
        "                                  new_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
        "                                  current_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
        "                                  new_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
        "                                  is_seg: bool = False,\n",
        "                                  order: int = 3, order_z: int = 0,\n",
        "                                  force_separate_z: Union[bool, None] = False,\n",
        "                                  separate_z_anisotropy_threshold: float = ANISO_THRESHOLD):\n",
        "    \"\"\"\n",
        "    needed for segmentation export. Stupid, I know\n",
        "    \"\"\"\n",
        "    if isinstance(data, torch.Tensor):\n",
        "        data = data.numpy()\n",
        "\n",
        "    do_separate_z, axis = determine_do_sep_z_and_axis(force_separate_z, current_spacing, new_spacing,\n",
        "                                                      separate_z_anisotropy_threshold)\n",
        "\n",
        "    if data is not None:\n",
        "        assert data.ndim == 4, \"data must be c x y z\"\n",
        "\n",
        "    data_reshaped = resample_data_or_seg(data, new_shape, is_seg, axis, order, do_separate_z, order_z=order_z)\n",
        "    return data_reshaped\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def convert_probabilities_to_segmentation(predicted_probabilities: Union[np.ndarray, torch.Tensor]) -> \\\n",
        "        Union[np.ndarray, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    assumes that inference_nonlinearity was already applied!\n",
        "\n",
        "    predicted_probabilities has to have shape (c, x, y(, z)) where c is the number of classes/regions\n",
        "    \"\"\"\n",
        "    if not isinstance(predicted_probabilities, (np.ndarray, torch.Tensor)):\n",
        "        raise RuntimeError(f\"Unexpected input type. Expected np.ndarray or torch.Tensor,\"\n",
        "                           f\" got {type(predicted_probabilities)}\")\n",
        "\n",
        "    # numpy is faster than torch. :facepalm:\n",
        "    is_numpy = isinstance(predicted_probabilities, np.ndarray)\n",
        "    if not is_numpy:\n",
        "        predicted_probabilities = predicted_probabilities.numpy()\n",
        "    segmentation = predicted_probabilities.argmax(0)\n",
        "    if not is_numpy:\n",
        "        segmentation = torch.from_numpy(segmentation)\n",
        "\n",
        "    return segmentation\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def convert_logits_to_segmentation(predicted_logits: Union[np.ndarray, torch.Tensor]) -> \\\n",
        "        Union[np.ndarray, torch.Tensor]:\n",
        "    input_is_numpy = isinstance(predicted_logits, np.ndarray)\n",
        "    # we can skip this step if we do not have region. Argmax is the same between logits or probabilities\n",
        "\n",
        "    probabilities = predicted_logits\n",
        "    if input_is_numpy and isinstance(probabilities, torch.Tensor):\n",
        "        probabilities = probabilities.cpu().numpy()\n",
        "    return convert_probabilities_to_segmentation(probabilities)"
      ],
      "metadata": {
        "id": "eo8kx60lOxPs",
        "ExecuteTime": {
          "end_time": "2025-03-29T23:21:05.723423Z",
          "start_time": "2025-03-29T23:21:01.084502Z"
        }
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "metadata": {
        "id": "qKjALJgiCR3N"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload Data"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_G76A3pCR3O",
        "outputId": "1ddae3c8-14e8-4cca-e266-51de1a6223d1"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "rm: cannot remove 'inference_test_cases': No such file or directory\n",
            "Archive:  inference_test_cases.zip\n",
            " extracting: inference_test_cases/FLARETs_0001_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0015_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0018_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0036_0000.nii.gz  \n",
            " extracting: inference_test_cases/FLARETs_0046_0000.nii.gz  \n",
            "rm: cannot remove 'inference_test_logit': No such file or directory\n",
            "Archive:  inference_test_logit.zip\n",
            "  inflating: inference_test_logit/FLARETs_0001.pt  \n",
            "  inflating: inference_test_logit/FLARETs_0015.pt  \n",
            "  inflating: inference_test_logit/FLARETs_0018.pt  \n",
            "  inflating: inference_test_logit/FLARETs_0036.pt  \n",
            "  inflating: inference_test_logit/FLARETs_0046.pt  \n"
          ]
        }
      ],
      "execution_count": 2,
      "source": [
        "from google.colab import drive\n",
        "from os import mkdir\n",
        "from os.path import exists\n",
        "from shutil import copy\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!rm -r inference_test_cases\n",
        "mkdir(\"inference_test_cases\")\n",
        "if not exists(\"inference_test_cases.zip\"):\n",
        "    copy(\"/content/drive/MyDrive/inference_test_cases.zip\", \"inference_test_cases.zip\")\n",
        "!unzip inference_test_cases.zip -d inference_test_cases\n",
        "\n",
        "!rm -r inference_test_logit\n",
        "mkdir(\"inference_test_logit\")\n",
        "if not exists(\"inference_test_logit.zip\"):\n",
        "    copy(\"/content/drive/MyDrive/inference_test_logit.zip\", \"inference_test_logit.zip\")\n",
        "!unzip inference_test_logit.zip -d inference_test_logit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls inference_test_logit -l --block-size=M"
      ],
      "metadata": {
        "id": "fbS8gwNC9DQ3",
        "outputId": "59115ac8-63a7-4491-8cea-14dc73962825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 5828M\n",
            "-rw-r--r-- 1 root root 1512M Mar 26 15:21 FLARETs_0001.pt\n",
            "-rw-r--r-- 1 root root 1385M Mar 26 15:15 FLARETs_0015.pt\n",
            "-rw-r--r-- 1 root root 1483M Mar 26 15:21 FLARETs_0018.pt\n",
            "-rw-r--r-- 1 root root  638M Mar 26 14:29 FLARETs_0036.pt\n",
            "-rw-r--r-- 1 root root  811M Mar 26 14:48 FLARETs_0046.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm inference_test_cases/FLARETs_0001_0000.nii.gz inference_test_logit/FLARETs_0001.pt inference_test_cases/FLARETs_0018_0000.nii.gz inference_test_logit/FLARETs_0018.pt inference_test_cases/FLARETs_0015_0000.nii.gz inference_test_logit/FLARETs_0015.pt"
      ],
      "metadata": {
        "id": "um_GPeQP9-Df"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6L4w8O7CR3O"
      },
      "cell_type": "markdown",
      "source": [
        "## Run Inference"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltDl7InDCR3O",
        "outputId": "57fc5fa1-951b-4d0f-ec15-c4cb09db80f3",
        "ExecuteTime": {
          "end_time": "2025-03-30T02:46:55.764600Z",
          "start_time": "2025-03-29T23:27:51.691118Z"
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from time import time\n",
        "from torch import load\n",
        "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
        "\n",
        "\n",
        "def main() -> dict[str, list[float]]:\n",
        "    CT_configuration = {\n",
        "        \"transpose_forward\": [\n",
        "            0,\n",
        "            1,\n",
        "            2\n",
        "        ],\n",
        "        \"spacing\": [\n",
        "            2.5,\n",
        "            0.7958984971046448,\n",
        "            0.7958984971046448\n",
        "        ],\n",
        "        'intensity_prop': {\n",
        "            \"max\": 3071.0,\n",
        "            \"mean\": 97.29716491699219,\n",
        "            \"median\": 118.0,\n",
        "            \"min\": -1024.0,\n",
        "            \"percentile_00_5\": -958.0,\n",
        "            \"percentile_99_5\": 270.0,\n",
        "            \"std\": 137.8484649658203\n",
        "        }}\n",
        "\n",
        "    cases = listdir(\"inference_test_cases\")\n",
        "    results = {\"resampling\": [], \"conversion\": []}\n",
        "    for case in cases:\n",
        "        image, properties = SimpleITKIO().read_images([f\"inference_test_cases/{case[:case.find('.')]}\"])\n",
        "        logit = load(f\"inference_test_logit/{case[:case.find('.')]}.pt\".replace(\"_0000\", \"\")).numpy()\n",
        "        data = image.astype(np.float32)\n",
        "        data = data.transpose([0, *[i + 1 for i in CT_configuration['transpose_forward']]])\n",
        "        shape_before_cropping = data.shape[1:]\n",
        "        properties['shape_before_cropping'] = shape_before_cropping\n",
        "        data, seg, bbox = crop_to_nonzero(data, None)\n",
        "        properties['bbox_used_for_cropping'] = bbox\n",
        "        properties['shape_after_cropping_and_before_resampling'] = data.shape[1:]\n",
        "        spacing_transposed = [properties['spacing'][i] for i in CT_configuration['transpose_forward']]\n",
        "        current_spacing = CT_configuration['spacing'] if len(CT_configuration['spacing']) == len(\n",
        "            properties['shape_after_cropping_and_before_resampling']) else [spacing_transposed[0],\n",
        "                                                                            *CT_configuration['spacing']]\n",
        "        t0 = time()\n",
        "        predicted_logit = resample_data_or_seg_to_shape(logit, properties['shape_after_cropping_and_before_resampling'],\n",
        "                                                        current_spacing, [properties['spacing'][i] for i in\n",
        "                                                                          CT_configuration['transpose_forward']])\n",
        "        results[\"resampling\"].append(time() - t0)\n",
        "        t0 = time()\n",
        "        convert_logits_to_segmentation(predicted_logit)\n",
        "        results[\"conversion\"].append(time() - t0)\n",
        "    return results\n",
        "\n",
        "\n",
        "def add_up(table: dict[str, list[float]], entry: str, n: int, num_cases: int) -> list[float]:\n",
        "    r = []\n",
        "    for i in range(num_cases):\n",
        "        s = 0\n",
        "        for j in range(n):\n",
        "            s += table[entry][i + j * num_cases]\n",
        "        r.append(s / n)\n",
        "    return r\n",
        "\n",
        "\n",
        "_final = {\"resampling\": [], \"conversion\": []}\n",
        "_n = 10\n",
        "_num_cases = 2\n",
        "for _b in range(_n):\n",
        "    print(f\"Porcessing batch {_b}\")\n",
        "    _r = main()\n",
        "    _final[\"resampling\"] += _r[\"resampling\"]\n",
        "    _final[\"conversion\"] += _r[\"conversion\"]\n",
        "print(add_up(_final, \"resampling\", _n, _num_cases))\n",
        "print(add_up(_final, \"conversion\", _n, _num_cases))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porcessing batch 0\n",
            "Porcessing batch 1\n",
            "Porcessing batch 2\n",
            "Porcessing batch 3\n",
            "Porcessing batch 4\n",
            "Porcessing batch 5\n",
            "Porcessing batch 6\n",
            "Porcessing batch 7\n",
            "Porcessing batch 8\n",
            "Porcessing batch 9\n",
            "[584.4420743227005, 217.17762620449065]\n",
            "[7.661114120483399, 2.7208886623382567]\n"
          ]
        }
      ],
      "execution_count": 5
    }
  ]
}