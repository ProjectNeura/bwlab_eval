{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install Dependencies",
   "id": "ed00eae0e9288950"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126",
   "id": "17ee79777044e05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip3 install nnunetv2 acvl-utils cupy-cuda12x",
   "id": "dacfbafc24beefd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Functions",
   "id": "26fc2e8d1f3219ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from abc import abstractmethod, ABC\n",
    "from typing import Optional, Dict, Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import torch\n",
    "from nnunetv2.configuration import ANISO_THRESHOLD\n",
    "from cupyx.scipy import ndimage\n",
    "from nnunetv2.utilities.helpers import empty_cache\n",
    "import gc\n",
    "\n",
    "CT_configuration = {\n",
    "    \"transpose_forward\": [\n",
    "        0,\n",
    "        1,\n",
    "        2\n",
    "    ],\n",
    "    \"spacing\": [\n",
    "                2.5,\n",
    "                0.7958984971046448,\n",
    "                0.7958984971046448\n",
    "            ],\n",
    "    'intensity_prop': {\n",
    "            \"max\": 3071.0,\n",
    "            \"mean\": 97.29716491699219,\n",
    "            \"median\": 118.0,\n",
    "            \"min\": -1024.0,\n",
    "            \"percentile_00_5\": -958.0,\n",
    "            \"percentile_99_5\": 270.0,\n",
    "            \"std\": 137.8484649658203\n",
    "        }}\n",
    "\n",
    "def logit_to_segment(predicted_logits):\n",
    "    max_logit, max_class = torch.max(predicted_logits, dim=0)\n",
    "    segmentation = torch.where(max_logit >= 0.5, max_class, torch.tensor(0, device=predicted_logits.device))\n",
    "\n",
    "    return segmentation\n",
    "\n",
    "def resize_by_chunk(torch_data, new_shape, chunk_size = 300):\n",
    "    torch_data = torch_data.detach().cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "    step = new_shape[0] // chunk_size + 1\n",
    "    seg_old_spacing = np.zeros(new_shape)\n",
    "    z = torch_data.shape[2]\n",
    "    stride = int(z / step)\n",
    "    step1 = [i * stride for i in range(step)] + [z]\n",
    "    z = new_shape[0]\n",
    "    stride = int(z / step)\n",
    "    step2 = [i * stride for i in range(step)] + [z]\n",
    "    for i in range(step):\n",
    "        size = list(new_shape)\n",
    "        size[0] = step2[i + 1] - step2[i]\n",
    "        slicer = torch_data[:,:, step1[i]:step1[i + 1]]#.half()\n",
    "        slicer = torch.nn.functional.interpolate(slicer.cuda(), mode='trilinear', size=size, align_corners=True)[0]\n",
    "        seg_old_spacing[step2[i]:step2[i + 1]] = logit_to_segment(slicer).cpu()\n",
    "        del slicer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.from_numpy(seg_old_spacing)\n",
    "\n",
    "def fast_resample_logit_to_shape(torch_data: Union[torch.Tensor, np.ndarray],\n",
    "                                  new_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                                  current_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                  new_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                  is_seg: bool = False,\n",
    "                                  order: int = 3, order_z: int = 0,\n",
    "                                  force_separate_z: Union[bool, None] = False,\n",
    "                                  separate_z_anisotropy_threshold: float = ANISO_THRESHOLD):\n",
    "    use_gpu = True\n",
    "    device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "    order_to_mode_map = {\n",
    "        0: \"nearest\",\n",
    "        1: \"trilinear\" if new_shape[0] > 1 else \"bilinear\",\n",
    "        2: \"trilinear\" if new_shape[0] > 1 else \"bilinear\",\n",
    "        3: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "        4: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "        5: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "    }\n",
    "    resize_fn = torch.nn.functional.interpolate\n",
    "    kwargs = {\n",
    "        'mode': order_to_mode_map[order],\n",
    "        'align_corners': False,\n",
    "    }\n",
    "    shape = np.array(torch_data[0].shape)\n",
    "    new_shape = np.array(new_shape)\n",
    "    if np.any(shape != new_shape):\n",
    "        if new_shape[0] == 1:\n",
    "            torch_data = torch_data.transpose(1, 0)\n",
    "            new_shape = new_shape[1:]\n",
    "        else:\n",
    "            torch_data = torch_data.unsqueeze(0)\n",
    "        gc.collect()\n",
    "        empty_cache(device)\n",
    "        if new_shape[0] < 600:\n",
    "            torch_data = resize_fn(torch_data.to(device), tuple(new_shape), **kwargs)\n",
    "\n",
    "            if new_shape[0] == 1:\n",
    "                torch_data = torch_data.transpose(1, 0)\n",
    "            else:\n",
    "                torch_data = torch_data.squeeze(0)\n",
    "        else:\n",
    "            torch_data = resize_by_chunk(torch_data.to(device), tuple(new_shape))\n",
    "        reshaped_final_data = torch_data\n",
    "        return reshaped_final_data\n",
    "    else:\n",
    "        print(\"no resampling necessary\")\n",
    "        return torch_data\n",
    "\n",
    "def convert_predicted_logits_to_segmentation_with_correct_shape(predicted_logits: Union[torch.Tensor, np.ndarray],\n",
    "                                                                properties_dict: dict,\n",
    "                                                                ):\n",
    "\n",
    "    spacing_transposed = [properties_dict['spacing'][i] for i in CT_configuration['transpose_forward']]\n",
    "    current_spacing = CT_configuration['spacing'] if \\\n",
    "        len(CT_configuration['spacing']) == \\\n",
    "        len(properties_dict['shape_after_cropping_and_before_resampling']) else \\\n",
    "        [spacing_transposed[0], *CT_configuration['spacing']]\n",
    "    predicted_logits = fast_resample_logit_to_shape(predicted_logits,\n",
    "                                            properties_dict['shape_after_cropping_and_before_resampling'],\n",
    "                                            current_spacing,\n",
    "                                            [properties_dict['spacing'][i] for i in CT_configuration['transpose_forward']])\n",
    "\n",
    "    segmentation = logit_to_segment(predicted_logits)\n",
    "    return segmentation\n",
    "\n",
    "\n",
    "class ImageNormalization(ABC):\n",
    "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = None\n",
    "\n",
    "    def __init__(self, use_mask_for_norm: Optional[bool] = None, intensityproperties: Optional[Dict] = None,\n",
    "                 target_dtype: torch.dtype = torch.float32):\n",
    "        assert use_mask_for_norm is None or isinstance(use_mask_for_norm, bool)\n",
    "        self.use_mask_for_norm = use_mask_for_norm\n",
    "        assert isinstance(intensityproperties, dict) or intensityproperties is None\n",
    "        self.intensityproperties = intensityproperties\n",
    "        self.target_dtype = target_dtype\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, image: torch.Tensor, seg: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class CTNormalization(ImageNormalization):\n",
    "    leaves_pixels_outside_mask_at_zero_if_use_mask_for_norm_is_true = False\n",
    "\n",
    "    def run(self, image: torch.Tensor, seg: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        assert self.intensityproperties is not None, \"CTNormalization requires intensity properties\"\n",
    "        mean_intensity = self.intensityproperties['mean']\n",
    "        std_intensity = self.intensityproperties['std']\n",
    "        lower_bound = self.intensityproperties['percentile_00_5']\n",
    "        upper_bound = self.intensityproperties['percentile_99_5']\n",
    "\n",
    "        image = image.to(dtype=self.target_dtype)\n",
    "        image = torch.clamp(image, lower_bound, upper_bound)\n",
    "        image = (image - mean_intensity) / max(std_intensity, 1e-8)\n",
    "        return image\n",
    "\n",
    "\n",
    "def create_nonzero_mask(data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :return: the mask is True where the data is nonzero\n",
    "    \"\"\"\n",
    "    assert data.ndim in (3, 4), \"data must have shape (C, X, Y, Z) or shape (C, X, Y)\"\n",
    "    nonzero_mask = data[0] != 0\n",
    "    for c in range(1, data.shape[0]):\n",
    "        nonzero_mask |= data[c] != 0\n",
    "    filled_mask = ndimage.binary_fill_holes(nonzero_mask)\n",
    "    return filled_mask\n",
    "\n",
    "\n",
    "def get_bbox_from_mask(mask: cp.ndarray) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    ALL bounding boxes in acvl_utils and nnU-Netv2 are half open interval [start, end)!\n",
    "    - Alignment with Python Slicing\n",
    "    - Ease of Subdivision\n",
    "    - Consistency in Multi-Dimensional Arrays\n",
    "    - Precedent in Computer Graphics\n",
    "\n",
    "    This implementation uses CuPy for GPU acceleration. The mask should be a CuPy array.\n",
    "\n",
    "    Args:\n",
    "        mask (cp.ndarray): 3D mask array on GPU\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: Bounding box coordinates as [[minz, maxz], [minx, maxx], [miny, maxy]]\n",
    "    \"\"\"\n",
    "    Z, X, Y = mask.shape\n",
    "    minzidx, maxzidx, minxidx, maxxidx, minyidx, maxyidx = 0, Z, 0, X, 0, Y\n",
    "\n",
    "    # Create range arrays on GPU\n",
    "    zidx = cp.arange(Z)\n",
    "    xidx = cp.arange(X)\n",
    "    yidx = cp.arange(Y)\n",
    "\n",
    "    # Z dimension\n",
    "    for z in zidx.get():  # .get() to iterate over CPU array\n",
    "        if cp.any(mask[z]).get():  # .get() to get boolean result to CPU\n",
    "            minzidx = z\n",
    "            break\n",
    "    for z in zidx[::-1].get():\n",
    "        if cp.any(mask[z]).get():\n",
    "            maxzidx = z + 1\n",
    "            break\n",
    "\n",
    "    # X dimension\n",
    "    for x in xidx.get():\n",
    "        if cp.any(mask[:, x]).get():\n",
    "            minxidx = x\n",
    "            break\n",
    "    for x in xidx[::-1].get():\n",
    "        if cp.any(mask[:, x]).get():\n",
    "            maxxidx = x + 1\n",
    "            break\n",
    "\n",
    "    # Y dimension\n",
    "    for y in yidx.get():\n",
    "        if cp.any(mask[:, :, y]).get():\n",
    "            minyidx = y\n",
    "            break\n",
    "    for y in yidx[::-1].get():\n",
    "        if cp.any(mask[:, :, y]).get():\n",
    "            maxyidx = y + 1\n",
    "            break\n",
    "\n",
    "    return [[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]]\n",
    "\n",
    "def bounding_box_to_slice(bounding_box: List[List[int]]):\n",
    "    \"\"\"\n",
    "    ALL bounding boxes in acvl_utils and nnU-Netv2 are half open interval [start, end)!\n",
    "    - Alignment with Python Slicing\n",
    "    - Ease of Subdivision\n",
    "    - Consistency in Multi-Dimensional Arrays\n",
    "    - Precedent in Computer Graphics\n",
    "    https://chatgpt.com/share/679203ec-3fbc-8013-a003-13a7adfb1e73\n",
    "    \"\"\"\n",
    "    return tuple([slice(*i) for i in bounding_box])\n",
    "\n",
    "\n",
    "def crop_to_nonzero(data, seg=None, nonzero_label=-1):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param seg:\n",
    "    :param nonzero_label: this will be written into the segmentation map\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nonzero_mask = create_nonzero_mask(data)\n",
    "    bbox = get_bbox_from_mask(nonzero_mask)\n",
    "    slicer = bounding_box_to_slice(bbox)\n",
    "    nonzero_mask = nonzero_mask[slicer][None]\n",
    "\n",
    "    slicer = (slice(None),) + slicer\n",
    "    data = data[slicer]\n",
    "    if seg is not None:\n",
    "        seg = seg[slicer]\n",
    "        seg[(seg == 0) & (~nonzero_mask)] = nonzero_label\n",
    "    else:\n",
    "        seg = np.where(nonzero_mask, np.int8(0), np.int8(nonzero_label))\n",
    "    return data, seg, bbox\n",
    "\n",
    "\n",
    "def compute_new_shape(old_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                      old_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                      new_spacing: Union[Tuple[float, ...], List[float], np.ndarray]) -> np.ndarray:\n",
    "    assert len(old_spacing) == len(old_shape)\n",
    "    assert len(old_shape) == len(new_spacing)\n",
    "    new_shape = np.array([int(round(i / j * k)) for i, j, k in zip(old_spacing, new_spacing, old_shape)])\n",
    "    return new_shape\n",
    "\n",
    "\n",
    "def fast_resample_data_or_seg_to_shape(data: Union[torch.Tensor, np.ndarray],\n",
    "                                       new_shape: Union[Tuple[int, ...], List[int], np.ndarray],\n",
    "                                       current_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                       new_spacing: Union[Tuple[float, ...], List[float], np.ndarray],\n",
    "                                       is_seg: bool = False,\n",
    "                                       order: int = 3, order_z: int = 0,\n",
    "                                       force_separate_z: Union[bool, None] = False,\n",
    "                                       separate_z_anisotropy_threshold: float = ANISO_THRESHOLD):\n",
    "    use_gpu = True\n",
    "    device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "    order_to_mode_map = {\n",
    "        0: \"nearest\",\n",
    "        1: \"trilinear\" if new_shape[0] > 1 else \"bilinear\",\n",
    "        2: \"trilinear\" if new_shape[0] > 1 else \"bilinear\",\n",
    "        3: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "        4: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "        5: \"trilinear\" if new_shape[0] > 1 else \"bicubic\",\n",
    "    }\n",
    "    resize_fn = torch.nn.functional.interpolate\n",
    "    kwargs = {\n",
    "        'mode': order_to_mode_map[order],\n",
    "        'align_corners': False\n",
    "    }\n",
    "    shape = np.array(data[0].shape)\n",
    "    new_shape = np.array(new_shape)\n",
    "    if np.any(shape != new_shape):\n",
    "        if not isinstance(data, torch.Tensor):\n",
    "            #torch_data = torch.from_numpy(data).float()\n",
    "            torch_data = torch.as_tensor(data.get())\n",
    "        else:\n",
    "            torch_data = data.float()\n",
    "        if new_shape[0] == 1:\n",
    "            torch_data = torch_data.transpose(1, 0)\n",
    "            new_shape = new_shape[1:]\n",
    "        else:\n",
    "            torch_data = torch_data.unsqueeze(0)\n",
    "\n",
    "        torch_data = resize_fn(torch_data.to(device), tuple(new_shape), **kwargs)\n",
    "\n",
    "        if new_shape[0] == 1:\n",
    "            torch_data = torch_data.transpose(1, 0)\n",
    "        else:\n",
    "            torch_data = torch_data.squeeze(0)\n",
    "\n",
    "        # if use_gpu:\n",
    "        #     torch_data = torch_data.cpu()\n",
    "        reshaped_final_data = torch_data\n",
    "        # if isinstance(data, np.ndarray):\n",
    "        #     reshaped_final_data = torch_data.numpy().astype(dtype_data)\n",
    "        # else:\n",
    "        #     reshaped_final_data = torch_data.to(dtype_data)\n",
    "\n",
    "        #print(f\"Reshaped data from {shape} to {new_shape}\")\n",
    "        #print(f\"reshaped_final_data shape: {reshaped_final_data.shape}\")\n",
    "        assert reshaped_final_data.ndim == 4, f\"reshaped_final_data.shape = {reshaped_final_data.shape}\"\n",
    "        return reshaped_final_data\n",
    "    else:\n",
    "        print(\"no resampling necessary\")\n",
    "        return data"
   ],
   "id": "3db77d43667d9a17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Inference",
   "id": "b628eb0a1d7a1ef4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from os import listdir\n",
    "from time import time\n",
    "from torch import load\n",
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "\n",
    "\n",
    "def main() -> dict[str, list[float]]:\n",
    "    cases = listdir(\"inference_test_cases\")\n",
    "    results = {\"resampling\": [], \"conversion\": []}\n",
    "    for case in cases:\n",
    "        image, properties = SimpleITKIO().read_images([f\"inference_test_cases/{case[:case.find('.')]}\"])\n",
    "        image = torch.from_numpy(image).to(dtype=torch.float32, memory_format=torch.contiguous_format).to('cuda')\n",
    "        data = image.clone()\n",
    "        data = data.permute([0, *[i + 1 for i in CT_configuration['transpose_forward']]])\n",
    "        shape_before_cropping = data.shape[1:]\n",
    "        properties['shape_before_cropping'] = shape_before_cropping\n",
    "        logit = load(f\"inference_test_logit/{case[:case.find('.')]}.pt\".replace(\"_0000\", \"\")).to(\"cuda\")\n",
    "        data, seg, bbox = crop_to_nonzero(data, None)\n",
    "        torch.cuda.synchronize()\n",
    "        properties['bbox_used_for_cropping'] = bbox\n",
    "        properties['shape_after_cropping_and_before_resampling'] = data.shape[1:]\n",
    "        spacing_transposed = [properties['spacing'][i] for i in CT_configuration['transpose_forward']]\n",
    "        current_spacing = CT_configuration['spacing'] if len(CT_configuration['spacing']) == len(\n",
    "            properties['shape_after_cropping_and_before_resampling']) else [spacing_transposed[0],\n",
    "                                                                            *CT_configuration['spacing']]\n",
    "        t0 = time()\n",
    "        predicted_logit = fast_resample_data_or_seg_to_shape(logit, properties['shape_after_cropping_and_before_resampling'],\n",
    "                                                        current_spacing, [properties['spacing'][i] for i in\n",
    "                                                                          CT_configuration['transpose_forward']])\n",
    "        torch.cuda.synchronize()\n",
    "        results[\"resampling\"].append(time() - t0)\n",
    "        t0 = time()\n",
    "        convert_predicted_logits_to_segmentation_with_correct_shape(predicted_logit)\n",
    "        results[\"conversion\"].append(time() - t0)\n",
    "    return results\n",
    "\n",
    "\n",
    "def add_up(table: dict[str, list[float]], entry: str, n: int, num_cases: int) -> list[float]:\n",
    "    r = []\n",
    "    for i in range(num_cases):\n",
    "        s = 0\n",
    "        for j in range(n):\n",
    "            s += table[entry][i + j * num_cases]\n",
    "        r.append(s / n)\n",
    "    return r\n",
    "\n",
    "\n",
    "_final = {\"resampling\": [], \"conversion\": []}\n",
    "_n = 10\n",
    "_num_cases = 5\n",
    "for _b in range(_n):\n",
    "    print(f\"Porcessing batch {_b}\")\n",
    "    _r = main()\n",
    "    _final[\"resampling\"] += _r[\"resampling\"]\n",
    "    _final[\"conversion\"] += _r[\"conversion\"]\n",
    "print(add_up(_final, \"resampling\", _n, _num_cases))\n",
    "print(add_up(_final, \"conversion\", _n, _num_cases))"
   ],
   "id": "a4d0f4b93211025b"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
